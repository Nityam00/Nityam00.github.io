Manifest.xml<br><br><?xml version="1.0" encoding="utf-8"?><br><manifest xmlns:android="http://schemas.android.com/apk/res/android"<br>    package="com.google.android.gms.samples.vision.ocrreader"<br>    android:installLocation="auto" ><br><br>    <uses-feature android:name="android.hardware.camera" /><br><br>    <uses-permission android:name="android.permission.CAMERA" /><br><br>    <application<br>        android:allowBackup="true"<br>        android:fullBackupContent="false"<br>        android:hardwareAccelerated="true"<br>        android:icon="@drawable/icon"<br>        android:label="OcrReaderApp"<br>        android:supportsRtl = "true"<br>        android:theme="@style/Theme.AppCompat" ><br>        <meta-data<br>            android:name="com.google.android.gms.version"<br>            android:value="@integer/google_play_services_version" /><br>        <meta-data<br>            android:name="com.google.android.gms.vision.DEPENDENCIES"<br>            android:value="ocr" /><br><br>        <activity android:name="com.google.android.gms.samples.vision.ocrreader.OcrCaptureActivity"<br>            android:label="Read Text"><br>            <intent-filter><br>                <action android:name="android.intent.action.MAIN" /><br>                <category android:name="android.intent.category.LAUNCHER" /><br>            </intent-filter><br>        </activity><br>    </application><br><br></manifest><br><br><br><br>ocr_capture.xml<br><br><?xml version="1.0" encoding="utf-8"?><br><br><LinearLayout<br>    xmlns:android="http://schemas.android.com/apk/res/android"<br>    android:id="@+id/topLayout"<br>    android:layout_width="match_parent"<br>    android:layout_height="match_parent"<br>    android:keepScreenOn="true"><br><br>    <com.google.android.gms.samples.vision.ocrreader.ui.camera.CameraSourcePreview<br>        android:id="@+id/preview"<br>        android:layout_width="match_parent"<br>        android:layout_height="match_parent"><br><br>        <com.google.android.gms.samples.vision.ocrreader.ui.camera.GraphicOverlay<br>            android:id="@+id/graphicOverlay"<br>            android:layout_width="match_parent"<br>            android:layout_height="match_parent" /><br><br>    </com.google.android.gms.samples.vision.ocrreader.ui.camera.CameraSourcePreview><br><br></LinearLayout><br><br>OcrCaptureActivity.java<br><br>package com.google.android.gms.samples.vision.ocrreader;<br><br>import android.Manifest;<br>import android.annotation.SuppressLint;<br>import android.app.Activity;<br>import android.app.AlertDialog;<br>import android.app.Dialog;<br>import android.content.Context;<br>import android.content.DialogInterface;<br>import android.content.Intent;<br>import android.content.IntentFilter;<br>import android.content.pm.PackageManager;<br>import android.hardware.Camera;<br>import android.os.Bundle;<br>import android.speech.tts.TextToSpeech;<br>import android.support.annotation.NonNull;<br>import android.support.design.widget.Snackbar;<br>import android.support.v4.app.ActivityCompat;<br>import android.support.v7.app.AppCompatActivity;<br>import android.util.Log;<br>import android.view.GestureDetector;<br>import android.view.MotionEvent;<br>import android.view.ScaleGestureDetector;<br>import android.view.View;<br>import android.widget.Toast;<br><br>import com.google.android.gms.common.ConnectionResult;<br>import com.google.android.gms.common.GoogleApiAvailability;<br>import com.google.android.gms.samples.vision.ocrreader.ui.camera.CameraSource;<br>import com.google.android.gms.samples.vision.ocrreader.ui.camera.CameraSourcePreview;<br>import com.google.android.gms.samples.vision.ocrreader.ui.camera.GraphicOverlay;<br>import com.google.android.gms.vision.text.TextBlock;<br>import com.google.android.gms.vision.text.TextRecognizer;<br><br>import java.io.IOException;<br>import java.util.Locale;<br><br>/**<br> * Activity for the Ocr Detecting app.  This app detects text and displays the value with the<br> * rear facing camera. During detection overlay graphics are drawn to indicate the position,<br> * size, and contents of each TextBlock.<br> */<br>public final class OcrCaptureActivity extends AppCompatActivity {<br>    private static final String TAG = "OcrCaptureActivity";<br><br>    // Intent request code to handle updating play services if needed.<br>    private static final int RC_HANDLE_GMS = 9001;<br><br>    // Permission request codes need to be < 256<br>    private static final int RC_HANDLE_CAMERA_PERM = 2;<br><br>    // Constants used to pass extra data in the intent<br>    public static final String AutoFocus = "AutoFocus";<br>    public static final String UseFlash = "UseFlash";<br>    public static final String TextBlockObject = "String";<br><br>    private CameraSource cameraSource;<br>    private CameraSourcePreview preview;<br>    private GraphicOverlay<OcrGraphic> graphicOverlay;<br><br>    // Helper objects for detecting taps and pinches.<br>    private ScaleGestureDetector scaleGestureDetector;<br>    private GestureDetector gestureDetector;<br><br>    // A TextToSpeech engine for speaking a String value.<br>    private TextToSpeech tts;<br><br>    /**<br>     * Initializes the UI and creates the detector pipeline.<br>     */<br>    @Override<br>    public void onCreate(Bundle bundle) {<br>        super.onCreate(bundle);<br>        setContentView(R.layout.ocr_capture);<br><br>        preview = (CameraSourcePreview) findViewById(R.id.preview);<br>        graphicOverlay = (GraphicOverlay<OcrGraphic>) findViewById(R.id.graphicOverlay);<br><br>        // Set good defaults for capturing text.<br>        boolean autoFocus = true;<br>        boolean useFlash = false;<br><br>        // Check for the camera permission before accessing the camera.  If the<br>        // permission is not granted yet, request permission.<br>        int rc = ActivityCompat.checkSelfPermission(this, Manifest.permission.CAMERA);<br>        if (rc == PackageManager.PERMISSION_GRANTED) {<br>            createCameraSource(autoFocus, useFlash);<br>        } else {<br>            requestCameraPermission();<br>        }<br><br>        gestureDetector = new GestureDetector(this, new CaptureGestureListener());<br>        scaleGestureDetector = new ScaleGestureDetector(this, new ScaleListener());<br><br>        Snackbar.make(graphicOverlay, "Tap to Speak. Pinch/Stretch to zoom",<br>                Snackbar.LENGTH_LONG)<br>                .show();<br><br>        // Set up the Text To Speech engine.<br>        TextToSpeech.OnInitListener listener =<br>                new TextToSpeech.OnInitListener() {<br>                    @Override<br>                    public void onInit(final int status) {<br>                        if (status == TextToSpeech.SUCCESS) {<br>                            Log.d("OnInitListener", "Text to speech engine started successfully.");<br>                            tts.setLanguage(Locale.US);<br>                        } else {<br>                            Log.d("OnInitListener", "Error starting the text to speech engine.");<br>                        }<br>                    }<br>                };<br>        tts = new TextToSpeech(this.getApplicationContext(), listener);<br>    }<br><br>    /**<br>     * Handles the requesting of the camera permission.  This includes<br>     * showing a "Snackbar" message of why the permission is needed then<br>     * sending the request.<br>     */<br>    private void requestCameraPermission() {<br>        Log.w(TAG, "Camera permission is not granted. Requesting permission");<br><br>        final String[] permissions = new String[]{Manifest.permission.CAMERA};<br><br>        if (!ActivityCompat.shouldShowRequestPermissionRationale(this,<br>                Manifest.permission.CAMERA)) {<br>            ActivityCompat.requestPermissions(this, permissions, RC_HANDLE_CAMERA_PERM);<br>            return;<br>        }<br><br>        final Activity thisActivity = this;<br><br>        View.OnClickListener listener = new View.OnClickListener() {<br>            @Override<br>            public void onClick(View view) {<br>                ActivityCompat.requestPermissions(thisActivity, permissions,<br>                        RC_HANDLE_CAMERA_PERM);<br>            }<br>        };<br><br>        Snackbar.make(graphicOverlay, R.string.permission_camera_rationale,<br>                Snackbar.LENGTH_INDEFINITE)<br>                .setAction(R.string.ok, listener)<br>                .show();<br>    }<br><br>    @Override<br>    public boolean onTouchEvent(MotionEvent e) {<br>        boolean b = scaleGestureDetector.onTouchEvent(e);<br><br>        boolean c = gestureDetector.onTouchEvent(e);<br><br>        return b || c || super.onTouchEvent(e);<br>    }<br><br>    /**<br>     * Creates and starts the camera.  Note that this uses a higher resolution in comparison<br>     * to other detection examples to enable the ocr detector to detect small text samples<br>     * at long distances.<br>     *<br>     * Suppressing InlinedApi since there is a check that the minimum version is met before using<br>     * the constant.<br>     */<br>    @SuppressLint("InlinedApi")<br>    private void createCameraSource(boolean autoFocus, boolean useFlash) {<br>        Context context = getApplicationContext();<br><br>        // A text recognizer is created to find text.  An associated multi-processor instance<br>        // is set to receive the text recognition results, track the text, and maintain<br>        // graphics for each text block on screen.  The factory is used by the multi-processor to<br>        // create a separate tracker instance for each text block.<br>        TextRecognizer textRecognizer = new TextRecognizer.Builder(context).build();<br>        textRecognizer.setProcessor(new OcrDetectorProcessor(graphicOverlay));<br><br>        if (!textRecognizer.isOperational()) {<br>            // Note: The first time that an app using a Vision API is installed on a<br>            // device, GMS will download a native libraries to the device in order to do detection.<br>            // Usually this completes before the app is run for the first time.  But if that<br>            // download has not yet completed, then the above call will not detect any text,<br>            // barcodes, or faces.<br>            //<br>            // isOperational() can be used to check if the required native libraries are currently<br>            // available.  The detectors will automatically become operational once the library<br>            // downloads complete on device.<br>            Log.w(TAG, "Detector dependencies are not yet available.");<br><br>            // Check for low storage.  If there is low storage, the native library will not be<br>            // downloaded, so detection will not become operational.<br>            IntentFilter lowstorageFilter = new IntentFilter(Intent.ACTION_DEVICE_STORAGE_LOW);<br>            boolean hasLowStorage = registerReceiver(null, lowstorageFilter) != null;<br><br>            if (hasLowStorage) {<br>                Toast.makeText(this, R.string.low_storage_error, Toast.LENGTH_LONG).show();<br>                Log.w(TAG, getString(R.string.low_storage_error));<br>            }<br>        }<br><br>        // Creates and starts the camera.  Note that this uses a higher resolution in comparison<br>        // to other detection examples to enable the text recognizer to detect small pieces of text.<br>        cameraSource =<br>                new CameraSource.Builder(getApplicationContext(), textRecognizer)<br>                .setFacing(CameraSource.CAMERA_FACING_BACK)<br>                .setRequestedPreviewSize(1280, 1024)<br>                .setRequestedFps(2.0f)<br>                .setFlashMode(useFlash ? Camera.Parameters.FLASH_MODE_TORCH : null)<br>                .setFocusMode(autoFocus ? Camera.Parameters.FOCUS_MODE_CONTINUOUS_VIDEO : null)<br>                .build();<br>    }<br><br>    /**<br>     * Restarts the camera.<br>     */<br>    @Override<br>    protected void onResume() {<br>        super.onResume();<br>        startCameraSource();<br>    }<br><br>    /**<br>     * Stops the camera.<br>     */<br>    @Override<br>    protected void onPause() {<br>        super.onPause();<br>        if (preview != null) {<br>            preview.stop();<br>        }<br>    }<br><br>    /**<br>     * Releases the resources associated with the camera source, the associated detectors, and the<br>     * rest of the processing pipeline.<br>     */<br>    @Override<br>    protected void onDestroy() {<br>        super.onDestroy();<br>        if (preview != null) {<br>            preview.release();<br>        }<br>    }<br><br>    /**<br>     * Callback for the result from requesting permissions. This method<br>     * is invoked for every call on {@link #requestPermissions(String[], int)}.<br>     * <p><br>     * <strong>Note:</strong> It is possible that the permissions request interaction<br>     * with the user is interrupted. In this case you will receive empty permissions<br>     * and results arrays which should be treated as a cancellation.<br>     * </p><br>     *<br>     * @param requestCode  The request code passed in {@link #requestPermissions(String[], int)}.<br>     * @param permissions  The requested permissions. Never null.<br>     * @param grantResults The grant results for the corresponding permissions<br>     *                     which is either {@link PackageManager#PERMISSION_GRANTED}<br>     *                     or {@link PackageManager#PERMISSION_DENIED}. Never null.<br>     * @see #requestPermissions(String[], int)<br>     */<br>    @Override<br>    public void onRequestPermissionsResult(int requestCode,<br>                                           @NonNull String[] permissions,<br>                                           @NonNull int[] grantResults) {<br>        if (requestCode != RC_HANDLE_CAMERA_PERM) {<br>            Log.d(TAG, "Got unexpected permission result: " + requestCode);<br>            super.onRequestPermissionsResult(requestCode, permissions, grantResults);<br>            return;<br>        }<br><br>        if (grantResults.length != 0 && grantResults[0] == PackageManager.PERMISSION_GRANTED) {<br>            Log.d(TAG, "Camera permission granted - initialize the camera source");<br>            // we have permission, so create the camerasource<br>            boolean autoFocus = getIntent().getBooleanExtra(AutoFocus,true);<br>            boolean useFlash = getIntent().getBooleanExtra(UseFlash, false);<br>            createCameraSource(autoFocus, useFlash);<br>            return;<br>        }<br><br>        Log.e(TAG, "Permission not granted: results len = " + grantResults.length +<br>                " Result code = " + (grantResults.length > 0 ? grantResults[0] : "(empty)"));<br><br>        DialogInterface.OnClickListener listener = new DialogInterface.OnClickListener() {<br>            public void onClick(DialogInterface dialog, int id) {<br>                finish();<br>            }<br>        };<br><br>        AlertDialog.Builder builder = new AlertDialog.Builder(this);<br>        builder.setTitle("Multitracker sample")<br>                .setMessage(R.string.no_camera_permission)<br>                .setPositiveButton(R.string.ok, listener)<br>                .show();<br>    }<br><br>    /**<br>     * Starts or restarts the camera source, if it exists.  If the camera source doesn't exist yet<br>     * (e.g., because onResume was called before the camera source was created), this will be called<br>     * again when the camera source is created.<br>     */<br>    private void startCameraSource() throws SecurityException {<br>        // check that the device has play services available.<br>        int code = GoogleApiAvailability.getInstance().isGooglePlayServicesAvailable(<br>                getApplicationContext());<br>        if (code != ConnectionResult.SUCCESS) {<br>            Dialog dlg =<br>                    GoogleApiAvailability.getInstance().getErrorDialog(this, code, RC_HANDLE_GMS);<br>            dlg.show();<br>        }<br><br>        if (cameraSource != null) {<br>            try {<br>                preview.start(cameraSource, graphicOverlay);<br>            } catch (IOException e) {<br>                Log.e(TAG, "Unable to start camera source.", e);<br>                cameraSource.release();<br>                cameraSource = null;<br>            }<br>        }<br>    }<br><br>    /**<br>     * onTap is called to speak the tapped TextBlock, if any, out loud.<br>     *<br>     * @param rawX - the raw position of the tap<br>     * @param rawY - the raw position of the tap.<br>     * @return true if the tap was on a TextBlock<br>     */<br>    private boolean onTap(float rawX, float rawY) {<br>        OcrGraphic graphic = graphicOverlay.getGraphicAtLocation(rawX, rawY);<br>        TextBlock text = null;<br>        if (graphic != null) {<br>            text = graphic.getTextBlock();<br>            if (text != null && text.getValue() != null) {<br>                Log.d(TAG, "text data is being spoken! " + text.getValue());<br>                // Speak the string.<br>                tts.speak(text.getValue(), TextToSpeech.QUEUE_ADD, null, "DEFAULT");<br>            }<br>            else {<br>                Log.d(TAG, "text data is null");<br>            }<br>        }<br>        else {<br>            Log.d(TAG,"no text detected");<br>        }<br>        return text != null;<br>    }<br><br>    private class CaptureGestureListener extends GestureDetector.SimpleOnGestureListener {<br><br>        @Override<br>        public boolean onSingleTapConfirmed(MotionEvent e) {<br>            return onTap(e.getRawX(), e.getRawY()) || super.onSingleTapConfirmed(e);<br>        }<br>    }<br><br>    private class ScaleListener implements ScaleGestureDetector.OnScaleGestureListener {<br><br>        /**<br>         * Responds to scaling events for a gesture in progress.<br>         * Reported by pointer motion.<br>         *<br>         * @param detector The detector reporting the event - use this to<br>         *                 retrieve extended info about event state.<br>         * @return Whether or not the detector should consider this event<br>         * as handled. If an event was not handled, the detector<br>         * will continue to accumulate movement until an event is<br>         * handled. This can be useful if an application, for example,<br>         * only wants to update scaling factors if the change is<br>         * greater than 0.01.<br>         */<br>        @Override<br>        public boolean onScale(ScaleGestureDetector detector) {<br>            return false;<br>        }<br><br>        /**<br>         * Responds to the beginning of a scaling gesture. Reported by<br>         * new pointers going down.<br>         *<br>         * @param detector The detector reporting the event - use this to<br>         *                 retrieve extended info about event state.<br>         * @return Whether or not the detector should continue recognizing<br>         * this gesture. For example, if a gesture is beginning<br>         * with a focal point outside of a region where it makes<br>         * sense, onScaleBegin() may return false to ignore the<br>         * rest of the gesture.<br>         */<br>        @Override<br>        public boolean onScaleBegin(ScaleGestureDetector detector) {<br>            return true;<br>        }<br><br>        /**<br>         * Responds to the end of a scale gesture. Reported by existing<br>         * pointers going up.<br>         * <p/><br>         * Once a scale has ended, {@link ScaleGestureDetector#getFocusX()}<br>         * and {@link ScaleGestureDetector#getFocusY()} will return focal point<br>         * of the pointers remaining on the screen.<br>         *<br>         * @param detector The detector reporting the event - use this to<br>         *                 retrieve extended info about event state.<br>         */<br>        @Override<br>        public void onScaleEnd(ScaleGestureDetector detector) {<br>            if (cameraSource != null) {<br>                cameraSource.doZoom(detector.getScaleFactor());<br>            }<br>        }<br>    }<br>}<br><br>OcrDetectorProcessor<br><br>package com.google.android.gms.samples.vision.ocrreader;<br><br>import android.util.Log;<br>import android.util.SparseArray;<br><br>import com.google.android.gms.samples.vision.ocrreader.ui.camera.GraphicOverlay;<br>import com.google.android.gms.vision.Detector;<br>import com.google.android.gms.vision.text.TextBlock;<br><br>/**<br> * A very simple Processor which gets detected TextBlocks and adds them to the overlay<br> * as OcrGraphics.<br> */<br>public class OcrDetectorProcessor implements Detector.Processor<TextBlock> {<br><br>    private GraphicOverlay<OcrGraphic> graphicOverlay;<br><br>    OcrDetectorProcessor(GraphicOverlay<OcrGraphic> ocrGraphicOverlay) {<br>        graphicOverlay = ocrGraphicOverlay;<br>    }<br><br>    /**<br>     * Called by the detector to deliver detection results.<br>     * If your application called for it, this could be a place to check for<br>     * equivalent detections by tracking TextBlocks that are similar in location and content from<br>     * previous frames, or reduce noise by eliminating TextBlocks that have not persisted through<br>     * multiple detections.<br>     */<br>    @Override<br>    public void receiveDetections(Detector.Detections<TextBlock> detections) {<br>        graphicOverlay.clear();<br>        SparseArray<TextBlock> items = detections.getDetectedItems();<br>        for (int i = 0; i < items.size(); ++i) {<br>            TextBlock item = items.valueAt(i);<br>            if (item != null && item.getValue() != null) {<br>                Log.d("OcrDetectorProcessor", "Text detected! " + item.getValue());<br>                OcrGraphic graphic = new OcrGraphic(graphicOverlay, item);<br>                graphicOverlay.add(graphic);<br>            }<br>        }<br>    }<br><br>    /**<br>     * Frees the resources associated with this detection processor.<br>     */<br>    @Override<br>    public void release() {<br>        graphicOverlay.clear();<br>    }<br>}<br><br>OcrGraphic.java<br><br>package com.google.android.gms.samples.vision.ocrreader;<br><br>import android.graphics.Canvas;<br>import android.graphics.Color;<br>import android.graphics.Paint;<br>import android.graphics.RectF;<br><br>import com.google.android.gms.samples.vision.ocrreader.ui.camera.GraphicOverlay;<br>import com.google.android.gms.vision.text.Text;<br>import com.google.android.gms.vision.text.TextBlock;<br><br>import java.util.List;<br><br>/**<br> * Graphic instance for rendering TextBlock position, size, and ID within an associated graphic<br> * overlay view.<br> */<br>public class OcrGraphic extends GraphicOverlay.Graphic {<br><br>    private int id;<br><br>    private static final int TEXT_COLOR = Color.WHITE;<br><br>    private static Paint rectPaint;<br>    private static Paint textPaint;<br>    private final TextBlock textBlock;<br><br>    OcrGraphic(GraphicOverlay overlay, TextBlock text) {<br>        super(overlay);<br><br>        textBlock = text;<br><br>        if (rectPaint == null) {<br>            rectPaint = new Paint();<br>            rectPaint.setColor(TEXT_COLOR);<br>            rectPaint.setStyle(Paint.Style.STROKE);<br>            rectPaint.setStrokeWidth(4.0f);<br>        }<br><br>        if (textPaint == null) {<br>            textPaint = new Paint();<br>            textPaint.setColor(TEXT_COLOR);<br>            textPaint.setTextSize(54.0f);<br>        }<br>        // Redraw the overlay, as this graphic has been added.<br>        postInvalidate();<br>    }<br><br>    public int getId() {<br>        return id;<br>    }<br><br>    public void setId(int id) {<br>        this.id = id;<br>    }<br><br>    public TextBlock getTextBlock() {<br>        return textBlock;<br>    }<br><br>    /**<br>     * Checks whether a point is within the bounding box of this graphic.<br>     * The provided point should be relative to this graphic's containing overlay.<br>     * @param x An x parameter in the relative context of the canvas.<br>     * @param y A y parameter in the relative context of the canvas.<br>     * @return True if the provided point is contained within this graphic's bounding box.<br>     */<br>    public boolean contains(float x, float y) {<br>        if (textBlock == null) {<br>            return false;<br>        }<br>        RectF rect = new RectF(textBlock.getBoundingBox());<br>        rect = translateRect(rect);<br>        return rect.contains(x, y);<br>    }<br><br>    /**<br>     * Draws the text block annotations for position, size, and raw value on the supplied canvas.<br>     */<br>    @Override<br>    public void draw(Canvas canvas) {<br>        if (textBlock == null) {<br>            return;<br>        }<br><br>        // Draws the bounding box around the TextBlock.<br>        RectF rect = new RectF(textBlock.getBoundingBox());<br>        rect = translateRect(rect);<br>        canvas.drawRect(rect, rectPaint);<br><br>        // Break the text into multiple lines and draw each one according to its own bounding box.<br>        List<? extends Text> textComponents = textBlock.getComponents();<br>        for(Text currentText : textComponents) {<br>            float left = translateX(currentText.getBoundingBox().left);<br>            float bottom = translateY(currentText.getBoundingBox().bottom);<br>            canvas.drawText(currentText.getValue(), left, bottom, textPaint);<br>        }<br>    }<br>}<br><br>CameraSource.java<br><br>package com.google.android.gms.samples.vision.ocrreader.ui.camera;<br><br>import android.Manifest;<br>import android.annotation.SuppressLint;<br>import android.annotation.TargetApi;<br>import android.content.Context;<br>import android.graphics.ImageFormat;<br>import android.graphics.SurfaceTexture;<br>import android.hardware.Camera;<br>import android.hardware.Camera.CameraInfo;<br>import android.os.Build;<br>import android.os.SystemClock;<br>import android.support.annotation.Nullable;<br>import android.support.annotation.RequiresPermission;<br>import android.support.annotation.StringDef;<br>import android.util.Log;<br>import android.view.Surface;<br>import android.view.SurfaceHolder;<br>import android.view.SurfaceView;<br>import android.view.WindowManager;<br><br>import com.google.android.gms.common.images.Size;<br>import com.google.android.gms.vision.Detector;<br>import com.google.android.gms.vision.Frame;<br><br>import java.io.IOException;<br>import java.lang.Thread.State;<br>import java.lang.annotation.Retention;<br>import java.lang.annotation.RetentionPolicy;<br>import java.nio.ByteBuffer;<br>import java.util.ArrayList;<br>import java.util.HashMap;<br>import java.util.List;<br>import java.util.Map;<br><br>// Note: This requires Google Play Services 8.1 or higher, due to using indirect byte buffers for<br>// storing images.<br><br>/**<br> * Manages the camera in conjunction with an underlying<br> * {@link com.google.android.gms.vision.Detector}.  This receives preview frames from the camera at<br> * a specified rate, sending those frames to the detector as fast as it is able to process those<br> * frames.<br> * <p/><br> * This camera source makes a best effort to manage processing on preview frames as fast as<br> * possible, while at the same time minimizing lag.  As such, frames may be dropped if the detector<br> * is unable to keep up with the rate of frames generated by the camera.  You should use<br> * {@link CameraSource.Builder#setRequestedFps(float)} to specify a frame rate that works well with<br> * the capabilities of the camera hardware and the detector options that you have selected.  If CPU<br> * utilization is higher than you'd like, then you may want to consider reducing FPS.  If the camera<br> * preview or detector results are too "jerky", then you may want to consider increasing FPS.<br> * <p/><br> * The following Android permission is required to use the camera:<br> * <ul><br> * <li>android.permissions.CAMERA</li><br> * </ul><br> */<br>@SuppressWarnings("deprecation")<br>public class CameraSource {<br>    @SuppressLint("InlinedApi")<br>    public static final int CAMERA_FACING_BACK = CameraInfo.CAMERA_FACING_BACK;<br>    @SuppressLint("InlinedApi")<br>    public static final int CAMERA_FACING_FRONT = CameraInfo.CAMERA_FACING_FRONT;<br><br>    private static final String TAG = "OpenCameraSource";<br><br>    /**<br>     * The dummy surface texture must be assigned a chosen name.  Since we never use an OpenGL<br>     * context, we can choose any ID we want here.<br>     */<br>    private static final int DUMMY_TEXTURE_NAME = 100;<br><br>    /**<br>     * If the absolute difference between a preview size aspect ratio and a picture size aspect<br>     * ratio is less than this tolerance, they are considered to be the same aspect ratio.<br>     */<br>    private static final float ASPECT_RATIO_TOLERANCE = 0.01f;<br><br>    @StringDef({<br>            Camera.Parameters.FOCUS_MODE_CONTINUOUS_PICTURE,<br>            Camera.Parameters.FOCUS_MODE_CONTINUOUS_VIDEO,<br>            Camera.Parameters.FOCUS_MODE_AUTO,<br>            Camera.Parameters.FOCUS_MODE_EDOF,<br>            Camera.Parameters.FOCUS_MODE_FIXED,<br>            Camera.Parameters.FOCUS_MODE_INFINITY,<br>            Camera.Parameters.FOCUS_MODE_MACRO<br>    })<br>    @Retention(RetentionPolicy.SOURCE)<br>    private @interface FocusMode {}<br><br>    @StringDef({<br>            Camera.Parameters.FLASH_MODE_ON,<br>            Camera.Parameters.FLASH_MODE_OFF,<br>            Camera.Parameters.FLASH_MODE_AUTO,<br>            Camera.Parameters.FLASH_MODE_RED_EYE,<br>            Camera.Parameters.FLASH_MODE_TORCH<br>    })<br>    @Retention(RetentionPolicy.SOURCE)<br>    private @interface FlashMode {}<br><br>    private Context context;<br><br>    private final Object cameraLock = new Object();<br><br>    // Guarded by cameraLock<br>    private Camera camera;<br><br>    private int mFacing = CAMERA_FACING_BACK;<br><br>    /**<br>     * Rotation of the device, and thus the associated preview images captured from the device.<br>     * See {@link Frame.Metadata#getRotation()}.<br>     */<br>    private int rotation;<br><br>    private Size previewSize;<br><br>    // These values may be requested by the caller.  Due to hardware limitations, we may need to<br>    // select close, but not exactly the same values for these.<br>    private float requestedFps = 30.0f;<br>    private int requestedPreviewWidth = 1024;<br>    private int requestedPreviewHeight = 768;<br><br><br>    private String focusMode = null;<br>    private String flashMode = null;<br><br>    // These instances need to be held onto to avoid GC of their underlying resources.  Even though<br>    // these aren't used outside of the method that creates them, they still must have hard<br>    // references maintained to them.<br>    private SurfaceView dummySurfaceView;<br>    private SurfaceTexture dummySurfaceTexture;<br><br>    /**<br>     * Dedicated thread and associated runnable for calling into the detector with frames, as the<br>     * frames become available from the camera.<br>     */<br>    private Thread processingThread;<br>    private FrameProcessingRunnable frameProcessor;<br><br>    /**<br>     * Map to convert between a byte array, received from the camera, and its associated byte<br>     * buffer.  We use byte buffers internally because this is a more efficient way to call into<br>     * native code later (avoids a potential copy).<br>     */<br>    private Map<byte[], ByteBuffer> bytesToByteBuffer = new HashMap<>();<br><br>    //==============================================================================================<br>    // Builder<br>    //==============================================================================================<br><br>    /**<br>     * Builder for configuring and creating an associated camera source.<br>     */<br>    public static class Builder {<br>        private final Detector<?> detector;<br>        private CameraSource cameraSource = new CameraSource();<br><br>        /**<br>         * Creates a camera source builder with the supplied context and detector.  Camera preview<br>         * images will be streamed to the associated detector upon starting the camera source.<br>         */<br>        public Builder(Context context, Detector<?> detector) {<br>            if (context == null) {<br>                throw new IllegalArgumentException("No context supplied.");<br>            }<br>            if (detector == null) {<br>                throw new IllegalArgumentException("No detector supplied.");<br>            }<br><br>            this.detector = detector;<br>            cameraSource.context = context;<br>        }<br><br>        /**<br>         * Sets the requested frame rate in frames per second.  If the exact requested value is not<br>         * not available, the best matching available value is selected.   Default: 30.<br>         */<br>        public Builder setRequestedFps(float fps) {<br>            if (fps <= 0) {<br>                throw new IllegalArgumentException("Invalid fps: " + fps);<br>            }<br>            cameraSource.requestedFps = fps;<br>            return this;<br>        }<br><br>        public Builder setFocusMode(@FocusMode String mode) {<br>            cameraSource.focusMode = mode;<br>            return this;<br>        }<br><br>        public Builder setFlashMode(@FlashMode String mode) {<br>            cameraSource.flashMode = mode;<br>            return this;<br>        }<br><br>        /**<br>         * Sets the desired width and height of the camera frames in pixels.  If the exact desired<br>         * values are not available options, the best matching available options are selected.<br>         * Also, we try to select a preview size which corresponds to the aspect ratio of an<br>         * associated full picture size, if applicable.  Default: 1024x768.<br>         */<br>        public Builder setRequestedPreviewSize(int width, int height) {<br>            // Restrict the requested range to something within the realm of possibility.  The<br>            // choice of 1000000 is a bit arbitrary -- intended to be well beyond resolutions that<br>            // devices can support.  We bound this to avoid int overflow in the code later.<br>            final int MAX = 1000000;<br>            if ((width <= 0) || (width > MAX) || (height <= 0) || (height > MAX)) {<br>                throw new IllegalArgumentException("Invalid preview size: " + width + "x" + height);<br>            }<br>            cameraSource.requestedPreviewWidth = width;<br>            cameraSource.requestedPreviewHeight = height;<br>            return this;<br>        }<br><br>        /**<br>         * Sets the camera to use (either {@link #CAMERA_FACING_BACK} or<br>         * {@link #CAMERA_FACING_FRONT}). Default: back facing.<br>         */<br>        public Builder setFacing(int facing) {<br>            if ((facing != CAMERA_FACING_BACK) && (facing != CAMERA_FACING_FRONT)) {<br>                throw new IllegalArgumentException("Invalid camera: " + facing);<br>            }<br>            cameraSource.mFacing = facing;<br>            return this;<br>        }<br><br>        /**<br>         * Creates an instance of the camera source.<br>         */<br>        public CameraSource build() {<br>            cameraSource.frameProcessor = cameraSource.new FrameProcessingRunnable(detector);<br>            return cameraSource;<br>        }<br>    }<br><br>    //==============================================================================================<br>    // Bridge Functionality for the Camera1 API<br>    //==============================================================================================<br><br>    /**<br>     * Callback interface used to signal the moment of actual image capture.<br>     */<br>    public interface ShutterCallback {<br>        /**<br>         * Called as near as possible to the moment when a photo is captured from the sensor. This<br>         * is a good opportunity to play a shutter sound or give other feedback of camera operation.<br>         * This may be some time after the photo was triggered, but some time before the actual data<br>         * is available.<br>         */<br>        void onShutter();<br>    }<br><br>    /**<br>     * Callback interface used to supply image data from a photo capture.<br>     */<br>    public interface PictureCallback {<br>        /**<br>         * Called when image data is available after a picture is taken.  The format of the data<br>         * is a jpeg binary.<br>         */<br>        void onPictureTaken(byte[] data);<br>    }<br><br>    /**<br>     * Callback interface used to notify on completion of camera auto focus.<br>     */<br>    public interface AutoFocusCallback {<br>        /**<br>         * Called when the camera auto focus completes.  If the camera<br>         * does not support auto-focus and autoFocus is called,<br>         * onAutoFocus will be called immediately with a fake value of<br>         * <code>success</code> set to <code>true</code>.<br>         * <p/><br>         * The auto-focus routine does not lock auto-exposure and auto-white<br>         * balance after it completes.<br>         *<br>         * @param success true if focus was successful, false if otherwise<br>         */<br>        void onAutoFocus(boolean success);<br>    }<br><br>    /**<br>     * Callback interface used to notify on auto focus start and stop.<br>     * <p/><br>     * <p>This is only supported in continuous autofocus modes -- {@link<br>     * Camera.Parameters#FOCUS_MODE_CONTINUOUS_VIDEO} and {@link<br>     * Camera.Parameters#FOCUS_MODE_CONTINUOUS_PICTURE}. Applications can show<br>     * autofocus animation based on this.</p><br>     */<br>    public interface AutoFocusMoveCallback {<br>        /**<br>         * Called when the camera auto focus starts or stops.<br>         *<br>         * @param start true if focus starts to move, false if focus stops to move<br>         */<br>        void onAutoFocusMoving(boolean start);<br>    }<br><br>    //==============================================================================================<br>    // Public<br>    //==============================================================================================<br><br>    /**<br>     * Stops the camera and releases the resources of the camera and underlying detector.<br>     */<br>    public void release() {<br>        synchronized (cameraLock) {<br>            stop();<br>            frameProcessor.release();<br>        }<br>    }<br><br>    /**<br>     * Opens the camera and starts sending preview frames to the underlying detector.  The preview<br>     * frames are not displayed.<br>     *<br>     * @throws IOException if the camera's preview texture or display could not be initialized<br>     */<br>    @RequiresPermission(Manifest.permission.CAMERA)<br>    public CameraSource start() throws IOException {<br>        synchronized (cameraLock) {<br>            if (camera != null) {<br>                return this;<br>            }<br><br>            camera = createCamera();<br><br>            // SurfaceTexture was introduced in Honeycomb (11), so if we are running and<br>            // old version of Android. fall back to use SurfaceView.<br>            if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.HONEYCOMB) {<br>                dummySurfaceTexture = new SurfaceTexture(DUMMY_TEXTURE_NAME);<br>                camera.setPreviewTexture(dummySurfaceTexture);<br>            } else {<br>                dummySurfaceView = new SurfaceView(context);<br>                camera.setPreviewDisplay(dummySurfaceView.getHolder());<br>            }<br>            camera.startPreview();<br><br>            processingThread = new Thread(frameProcessor);<br>            frameProcessor.setActive(true);<br>            processingThread.start();<br>        }<br>        return this;<br>    }<br><br>    /**<br>     * Opens the camera and starts sending preview frames to the underlying detector.  The supplied<br>     * surface holder is used for the preview so frames can be displayed to the user.<br>     *<br>     * @param surfaceHolder the surface holder to use for the preview frames<br>     * @throws IOException if the supplied surface holder could not be used as the preview display<br>     */<br>    @RequiresPermission(Manifest.permission.CAMERA)<br>    public CameraSource start(SurfaceHolder surfaceHolder) throws IOException {<br>        synchronized (cameraLock) {<br>            if (camera != null) {<br>                return this;<br>            }<br><br>            camera = createCamera();<br>            camera.setPreviewDisplay(surfaceHolder);<br>            camera.startPreview();<br><br>            processingThread = new Thread(frameProcessor);<br>            frameProcessor.setActive(true);<br>            processingThread.start();<br>        }<br>        return this;<br>    }<br><br>    /**<br>     * Closes the camera and stops sending frames to the underlying frame detector.<br>     * <p/><br>     * This camera source may be restarted again by calling {@link #start()} or<br>     * {@link #start(SurfaceHolder)}.<br>     * <p/><br>     * Call {@link #release()} instead to completely shut down this camera source and release the<br>     * resources of the underlying detector.<br>     */<br>    public void stop() {<br>        synchronized (cameraLock) {<br>            frameProcessor.setActive(false);<br>            if (processingThread != null) {<br>                try {<br>                    // Wait for the thread to complete to ensure that we can't have multiple threads<br>                    // executing at the same time (i.e., which would happen if we called start too<br>                    // quickly after stop).<br>                    processingThread.join();<br>                } catch (InterruptedException e) {<br>                    Log.d(TAG, "Frame processing thread interrupted on release.");<br>                }<br>                processingThread = null;<br>            }<br><br>            // clear the buffer to prevent oom exceptions<br>            bytesToByteBuffer.clear();<br><br>            if (camera != null) {<br>                camera.stopPreview();<br>                camera.setPreviewCallbackWithBuffer(null);<br>                try {<br>                    // We want to be compatible back to Gingerbread, but SurfaceTexture<br>                    // wasn't introduced until Honeycomb.  Since the interface cannot use a<br>                    // SurfaceTexture, if the developer wants to display a preview we must use a<br>                    // SurfaceHolder.  If the developer doesn't want to display a preview we use a<br>                    // SurfaceTexture if we are running at least Honeycomb.<br><br>                    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.HONEYCOMB) {<br>                        camera.setPreviewTexture(null);<br><br>                    } else {<br>                        camera.setPreviewDisplay(null);<br>                    }<br>                } catch (Exception e) {<br>                    Log.e(TAG, "Failed to clear camera preview: " + e);<br>                }<br>                camera.release();<br>                camera = null;<br>            }<br>        }<br>    }<br><br>    /**<br>     * Returns the preview size that is currently in use by the underlying camera.<br>     */<br>    public Size getPreviewSize() {<br>        return previewSize;<br>    }<br><br>    /**<br>     * Returns the selected camera; one of {@link #CAMERA_FACING_BACK} or<br>     * {@link #CAMERA_FACING_FRONT}.<br>     */<br>    public int getCameraFacing() {<br>        return mFacing;<br>    }<br><br>    public int doZoom(float scale) {<br>        synchronized (cameraLock) {<br>            if (camera == null) {<br>                return 0;<br>            }<br>            int currentZoom = 0;<br>            int maxZoom;<br>            Camera.Parameters parameters = camera.getParameters();<br>            if (!parameters.isZoomSupported()) {<br>                Log.w(TAG, "Zoom is not supported on this device");<br>                return currentZoom;<br>            }<br>            maxZoom = parameters.getMaxZoom();<br><br>            currentZoom = parameters.getZoom() + 1;<br>            float newZoom;<br>            if (scale > 1) {<br>                newZoom = currentZoom + scale * (maxZoom / 10);<br>            } else {<br>                newZoom = currentZoom * scale;<br>            }<br>            currentZoom = Math.round(newZoom) - 1;<br>            if (currentZoom < 0) {<br>                currentZoom = 0;<br>            } else if (currentZoom > maxZoom) {<br>                currentZoom = maxZoom;<br>            }<br>            parameters.setZoom(currentZoom);<br>            camera.setParameters(parameters);<br>            return currentZoom;<br>        }<br>    }<br><br>    /**<br>     * Initiates taking a picture, which happens asynchronously.  The camera source should have been<br>     * activated previously with {@link #start()} or {@link #start(SurfaceHolder)}.  The camera<br>     * preview is suspended while the picture is being taken, but will resume once picture taking is<br>     * done.<br>     *<br>     * @param shutter the callback for image capture moment, or null<br>     * @param jpeg    the callback for JPEG image data, or null<br>     */<br>    public void takePicture(ShutterCallback shutter, PictureCallback jpeg) {<br>        synchronized (cameraLock) {<br>            if (camera != null) {<br>                PictureStartCallback startCallback = new PictureStartCallback();<br>                startCallback.mDelegate = shutter;<br>                PictureDoneCallback doneCallback = new PictureDoneCallback();<br>                doneCallback.mDelegate = jpeg;<br>                camera.takePicture(startCallback, null, null, doneCallback);<br>            }<br>        }<br>    }<br><br>    /**<br>     * Gets the current focus mode setting.<br>     *<br>     * @return current focus mode. This value is null if the camera is not yet created.<br>     * Applications should call {@link #autoFocus(AutoFocusCallback)} to start the focus if focus<br>     * mode is FOCUS_MODE_AUTO or FOCUS_MODE_MACRO.<br>     * @see Camera.Parameters#FOCUS_MODE_AUTO<br>     * @see Camera.Parameters#FOCUS_MODE_INFINITY<br>     * @see Camera.Parameters#FOCUS_MODE_MACRO<br>     * @see Camera.Parameters#FOCUS_MODE_FIXED<br>     * @see Camera.Parameters#FOCUS_MODE_EDOF<br>     * @see Camera.Parameters#FOCUS_MODE_CONTINUOUS_VIDEO<br>     * @see Camera.Parameters#FOCUS_MODE_CONTINUOUS_PICTURE<br>     */<br>    @Nullable<br>    @FocusMode<br>    public String getFocusMode() {<br>        return focusMode;<br>    }<br><br>    /**<br>     * Sets the focus mode.<br>     *<br>     * @param mode the focus mode<br>     * @return {@code true} if the focus mode is set, {@code false} otherwise<br>     * @see #getFocusMode()<br>     */<br>    public boolean setFocusMode(@FocusMode String mode) {<br>        synchronized (cameraLock) {<br>            if (camera != null && mode != null) {<br>                Camera.Parameters parameters = camera.getParameters();<br>                if (parameters.getSupportedFocusModes().contains(mode)) {<br>                    parameters.setFocusMode(mode);<br>                    camera.setParameters(parameters);<br>                    focusMode = mode;<br>                    return true;<br>                }<br>            }<br><br>            return false;<br>        }<br>    }<br><br>    /**<br>     * Gets the current flash mode setting.<br>     *<br>     * @return current flash mode. null if flash mode setting is not<br>     * supported or the camera is not yet created.<br>     * @see Camera.Parameters#FLASH_MODE_OFF<br>     * @see Camera.Parameters#FLASH_MODE_AUTO<br>     * @see Camera.Parameters#FLASH_MODE_ON<br>     * @see Camera.Parameters#FLASH_MODE_RED_EYE<br>     * @see Camera.Parameters#FLASH_MODE_TORCH<br>     */<br>    @Nullable<br>    @FlashMode<br>    public String getFlashMode() {<br>        return flashMode;<br>    }<br><br>    /**<br>     * Sets the flash mode.<br>     *<br>     * @param mode flash mode.<br>     * @return {@code true} if the flash mode is set, {@code false} otherwise<br>     * @see #getFlashMode()<br>     */<br>    public boolean setFlashMode(@FlashMode String mode) {<br>        synchronized (cameraLock) {<br>            if (camera != null && mode != null) {<br>                Camera.Parameters parameters = camera.getParameters();<br>                if (parameters.getSupportedFlashModes().contains(mode)) {<br>                    parameters.setFlashMode(mode);<br>                    camera.setParameters(parameters);<br>                    flashMode = mode;<br>                    return true;<br>                }<br>            }<br><br>            return false;<br>        }<br>    }<br><br>    /**<br>     * Starts camera auto-focus and registers a callback function to run when<br>     * the camera is focused.  This method is only valid when preview is active<br>     * (between {@link #start()} or {@link #start(SurfaceHolder)} and before {@link #stop()}<br>     * or {@link #release()}).<br>     * <p/><br>     * <p>Callers should check<br>     * {@link #getFocusMode()} to determine if<br>     * this method should be called. If the camera does not support auto-focus,<br>     * it is a no-op and {@link AutoFocusCallback#onAutoFocus(boolean)}<br>     * callback will be called immediately.<br>     * <p/><br>     * <p>If the current flash mode is not<br>     * {@link Camera.Parameters#FLASH_MODE_OFF}, flash may be<br>     * fired during auto-focus, depending on the driver and camera hardware.<p><br>     *<br>     * @param cb the callback to run<br>     * @see #cancelAutoFocus()<br>     */<br>    public void autoFocus(@Nullable AutoFocusCallback cb) {<br>        synchronized (cameraLock) {<br>            if (camera != null) {<br>                CameraAutoFocusCallback autoFocusCallback = null;<br>                if (cb != null) {<br>                    autoFocusCallback = new CameraAutoFocusCallback();<br>                    autoFocusCallback.mDelegate = cb;<br>                }<br>                camera.autoFocus(autoFocusCallback);<br>            }<br>        }<br>    }<br><br>    /**<br>     * Cancels any auto-focus function in progress.<br>     * Whether or not auto-focus is currently in progress,<br>     * this function will return the focus position to the default.<br>     * If the camera does not support auto-focus, this is a no-op.<br>     *<br>     * @see #autoFocus(AutoFocusCallback)<br>     */<br>    public void cancelAutoFocus() {<br>        synchronized (cameraLock) {<br>            if (camera != null) {<br>                camera.cancelAutoFocus();<br>            }<br>        }<br>    }<br><br>    /**<br>     * Sets camera auto-focus move callback.<br>     *<br>     * @param cb the callback to run<br>     * @return {@code true} if the operation is supported (i.e. from Jelly Bean), {@code false}<br>     * otherwise<br>     */<br>    @TargetApi(Build.VERSION_CODES.JELLY_BEAN)<br>    public boolean setAutoFocusMoveCallback(@Nullable AutoFocusMoveCallback cb) {<br>        if (Build.VERSION.SDK_INT < Build.VERSION_CODES.JELLY_BEAN) {<br>            return false;<br>        }<br><br>        synchronized (cameraLock) {<br>            if (camera != null) {<br>                CameraAutoFocusMoveCallback autoFocusMoveCallback = null;<br>                if (cb != null) {<br>                    autoFocusMoveCallback = new CameraAutoFocusMoveCallback();<br>                    autoFocusMoveCallback.mDelegate = cb;<br>                }<br>                camera.setAutoFocusMoveCallback(autoFocusMoveCallback);<br>            }<br>        }<br><br>        return true;<br>    }<br><br>    //==============================================================================================<br>    // Private<br>    //==============================================================================================<br><br>    /**<br>     * Only allow creation via the builder class.<br>     */<br>    private CameraSource() {<br>    }<br><br>    /**<br>     * Wraps the camera1 shutter callback so that the deprecated API isn't exposed.<br>     */<br>    private class PictureStartCallback implements Camera.ShutterCallback {<br>        private ShutterCallback mDelegate;<br><br>        @Override<br>        public void onShutter() {<br>            if (mDelegate != null) {<br>                mDelegate.onShutter();<br>            }<br>        }<br>    }<br><br>    /**<br>     * Wraps the final callback in the camera sequence, so that we can automatically turn the camera<br>     * preview back on after the picture has been taken.<br>     */<br>    private class PictureDoneCallback implements Camera.PictureCallback {<br>        private PictureCallback mDelegate;<br><br>        @Override<br>        public void onPictureTaken(byte[] data, Camera camera) {<br>            if (mDelegate != null) {<br>                mDelegate.onPictureTaken(data);<br>            }<br>            synchronized (cameraLock) {<br>                if (CameraSource.this.camera != null) {<br>                    CameraSource.this.camera.startPreview();<br>                }<br>            }<br>        }<br>    }<br><br>    /**<br>     * Wraps the camera1 auto focus callback so that the deprecated API isn't exposed.<br>     */<br>    private class CameraAutoFocusCallback implements Camera.AutoFocusCallback {<br>        private AutoFocusCallback mDelegate;<br><br>        @Override<br>        public void onAutoFocus(boolean success, Camera camera) {<br>            if (mDelegate != null) {<br>                mDelegate.onAutoFocus(success);<br>            }<br>        }<br>    }<br><br>    /**<br>     * Wraps the camera1 auto focus move callback so that the deprecated API isn't exposed.<br>     */<br>    @TargetApi(Build.VERSION_CODES.JELLY_BEAN)<br>    private class CameraAutoFocusMoveCallback implements Camera.AutoFocusMoveCallback {<br>        private AutoFocusMoveCallback mDelegate;<br><br>        @Override<br>        public void onAutoFocusMoving(boolean start, Camera camera) {<br>            if (mDelegate != null) {<br>                mDelegate.onAutoFocusMoving(start);<br>            }<br>        }<br>    }<br><br>    /**<br>     * Opens the camera and applies the user settings.<br>     *<br>     * @throws RuntimeException if the method fails<br>     */<br>    @SuppressLint("InlinedApi")<br>    private Camera createCamera() {<br>        int requestedCameraId = getIdForRequestedCamera(mFacing);<br>        if (requestedCameraId == -1) {<br>            throw new RuntimeException("Could not find requested camera.");<br>        }<br>        Camera camera = Camera.open(requestedCameraId);<br><br>        SizePair sizePair = selectSizePair(camera, requestedPreviewWidth, requestedPreviewHeight);<br>        if (sizePair == null) {<br>            throw new RuntimeException("Could not find suitable preview size.");<br>        }<br>        Size pictureSize = sizePair.pictureSize();<br>        previewSize = sizePair.previewSize();<br><br>        int[] previewFpsRange = selectPreviewFpsRange(camera, requestedFps);<br>        if (previewFpsRange == null) {<br>            throw new RuntimeException("Could not find suitable preview frames per second range.");<br>        }<br><br>        Camera.Parameters parameters = camera.getParameters();<br><br>        if (pictureSize != null) {<br>            parameters.setPictureSize(pictureSize.getWidth(), pictureSize.getHeight());<br>        }<br><br>        parameters.setPreviewSize(previewSize.getWidth(), previewSize.getHeight());<br>        parameters.setPreviewFpsRange(<br>                previewFpsRange[Camera.Parameters.PREVIEW_FPS_MIN_INDEX],<br>                previewFpsRange[Camera.Parameters.PREVIEW_FPS_MAX_INDEX]);<br>        parameters.setPreviewFormat(ImageFormat.NV21);<br><br>        setRotation(camera, parameters, requestedCameraId);<br><br>        if (focusMode != null) {<br>            if (parameters.getSupportedFocusModes().contains(<br>                    focusMode)) {<br>                parameters.setFocusMode(focusMode);<br>            } else {<br>                Log.i(TAG, "Camera focus mode: " + focusMode +<br>                        " is not supported on this device.");<br>            }<br>        }<br><br>        // setting focusMode to the one set in the params<br>        focusMode = parameters.getFocusMode();<br><br>        if (flashMode != null) {<br>            if (parameters.getSupportedFlashModes().contains(<br>                    flashMode)) {<br>                parameters.setFlashMode(flashMode);<br>            } else {<br>                Log.i(TAG, "Camera flash mode: " + flashMode +<br>                        " is not supported on this device.");<br>            }<br>        }<br><br>        // setting flashMode to the one set in the params<br>        flashMode = parameters.getFlashMode();<br><br>        camera.setParameters(parameters);<br><br>        // Four frame buffers are needed for working with the camera:<br>        //<br>        //   one for the frame that is currently being executed upon in doing detection<br>        //   one for the next pending frame to process immediately upon completing detection<br>        //   two for the frames that the camera uses to populate future preview images<br>        camera.setPreviewCallbackWithBuffer(new CameraPreviewCallback());<br>        camera.addCallbackBuffer(createPreviewBuffer(previewSize));<br>        camera.addCallbackBuffer(createPreviewBuffer(previewSize));<br>        camera.addCallbackBuffer(createPreviewBuffer(previewSize));<br>        camera.addCallbackBuffer(createPreviewBuffer(previewSize));<br><br>        return camera;<br>    }<br><br>    /**<br>     * Gets the id for the camera specified by the direction it is facing.  Returns -1 if no such<br>     * camera was found.<br>     *<br>     * @param facing the desired camera (front-facing or rear-facing)<br>     */<br>    private static int getIdForRequestedCamera(int facing) {<br>        CameraInfo cameraInfo = new CameraInfo();<br>        for (int i = 0; i < Camera.getNumberOfCameras(); ++i) {<br>            Camera.getCameraInfo(i, cameraInfo);<br>            if (cameraInfo.facing == facing) {<br>                return i;<br>            }<br>        }<br>        return -1;<br>    }<br><br>    /**<br>     * Selects the most suitable preview and picture size, given the desired width and height.<br>     * <p/><br>     * Even though we may only need the preview size, it's necessary to find both the preview<br>     * size and the picture size of the camera together, because these need to have the same aspect<br>     * ratio.  On some hardware, if you would only set the preview size, you will get a distorted<br>     * image.<br>     *<br>     * @param camera        the camera to select a preview size from<br>     * @param desiredWidth  the desired width of the camera preview frames<br>     * @param desiredHeight the desired height of the camera preview frames<br>     * @return the selected preview and picture size pair<br>     */<br>    private static SizePair selectSizePair(Camera camera, int desiredWidth, int desiredHeight) {<br>        List<SizePair> validPreviewSizes = generateValidPreviewSizeList(camera);<br><br>        // The method for selecting the best size is to minimize the sum of the differences between<br>        // the desired values and the actual values for width and height.  This is certainly not the<br>        // only way to select the best size, but it provides a decent tradeoff between using the<br>        // closest aspect ratio vs. using the closest pixel area.<br>        SizePair selectedPair = null;<br>        int minDiff = Integer.MAX_VALUE;<br>        for (SizePair sizePair : validPreviewSizes) {<br>            Size size = sizePair.previewSize();<br>            int diff = Math.abs(size.getWidth() - desiredWidth) +<br>                    Math.abs(size.getHeight() - desiredHeight);<br>            if (diff < minDiff) {<br>                selectedPair = sizePair;<br>                minDiff = diff;<br>            }<br>        }<br><br>        return selectedPair;<br>    }<br><br>    /**<br>     * Stores a preview size and a corresponding same-aspect-ratio picture size.  To avoid distorted<br>     * preview images on some devices, the picture size must be set to a size that is the same<br>     * aspect ratio as the preview size or the preview may end up being distorted.  If the picture<br>     * size is null, then there is no picture size with the same aspect ratio as the preview size.<br>     */<br>    private static class SizePair {<br>        private Size mPreview;<br>        private Size mPicture;<br><br>        public SizePair(android.hardware.Camera.Size previewSize,<br>                        android.hardware.Camera.Size pictureSize) {<br>            mPreview = new Size(previewSize.width, previewSize.height);<br>            if (pictureSize != null) {<br>                mPicture = new Size(pictureSize.width, pictureSize.height);<br>            }<br>        }<br><br>        public Size previewSize() {<br>            return mPreview;<br>        }<br><br>        @SuppressWarnings("unused")<br>        public Size pictureSize() {<br>            return mPicture;<br>        }<br>    }<br><br>    /**<br>     * Generates a list of acceptable preview sizes.  Preview sizes are not acceptable if there is<br>     * not a corresponding picture size of the same aspect ratio.  If there is a corresponding<br>     * picture size of the same aspect ratio, the picture size is paired up with the preview size.<br>     * <p/><br>     * This is necessary because even if we don't use still pictures, the still picture size must be<br>     * set to a size that is the same aspect ratio as the preview size we choose.  Otherwise, the<br>     * preview images may be distorted on some devices.<br>     */<br>    private static List<SizePair> generateValidPreviewSizeList(Camera camera) {<br>        Camera.Parameters parameters = camera.getParameters();<br>        List<android.hardware.Camera.Size> supportedPreviewSizes =<br>                parameters.getSupportedPreviewSizes();<br>        List<android.hardware.Camera.Size> supportedPictureSizes =<br>                parameters.getSupportedPictureSizes();<br>        List<SizePair> validPreviewSizes = new ArrayList<>();<br>        for (android.hardware.Camera.Size previewSize : supportedPreviewSizes) {<br>            float previewAspectRatio = (float) previewSize.width / (float) previewSize.height;<br><br>            // By looping through the picture sizes in order, we favor the higher resolutions.<br>            // We choose the highest resolution in order to support taking the full resolution<br>            // picture later.<br>            for (android.hardware.Camera.Size pictureSize : supportedPictureSizes) {<br>                float pictureAspectRatio = (float) pictureSize.width / (float) pictureSize.height;<br>                if (Math.abs(previewAspectRatio - pictureAspectRatio) < ASPECT_RATIO_TOLERANCE) {<br>                    validPreviewSizes.add(new SizePair(previewSize, pictureSize));<br>                    break;<br>                }<br>            }<br>        }<br><br>        // If there are no picture sizes with the same aspect ratio as any preview sizes, allow all<br>        // of the preview sizes and hope that the camera can handle it.  Probably unlikely, but we<br>        // still account for it.<br>        if (validPreviewSizes.size() == 0) {<br>            Log.w(TAG, "No preview sizes have a corresponding same-aspect-ratio picture size");<br>            for (android.hardware.Camera.Size previewSize : supportedPreviewSizes) {<br>                // The null picture size will let us know that we shouldn't set a picture size.<br>                validPreviewSizes.add(new SizePair(previewSize, null));<br>            }<br>        }<br><br>        return validPreviewSizes;<br>    }<br><br>    /**<br>     * Selects the most suitable preview frames per second range, given the desired frames per<br>     * second.<br>     *<br>     * @param camera            the camera to select a frames per second range from<br>     * @param desiredPreviewFps the desired frames per second for the camera preview frames<br>     * @return the selected preview frames per second range<br>     */<br>    private int[] selectPreviewFpsRange(Camera camera, float desiredPreviewFps) {<br>        // The camera API uses integers scaled by a factor of 1000 instead of floating-point frame<br>        // rates.<br>        int desiredPreviewFpsScaled = (int) (desiredPreviewFps * 1000.0f);<br><br>        // The method for selecting the best range is to minimize the sum of the differences between<br>        // the desired value and the upper and lower bounds of the range.  This may select a range<br>        // that the desired value is outside of, but this is often preferred.  For example, if the<br>        // desired frame rate is 29.97, the range (30, 30) is probably more desirable than the<br>        // range (15, 30).<br>        int[] selectedFpsRange = null;<br>        int minDiff = Integer.MAX_VALUE;<br>        List<int[]> previewFpsRangeList = camera.getParameters().getSupportedPreviewFpsRange();<br>        for (int[] range : previewFpsRangeList) {<br>            int deltaMin = desiredPreviewFpsScaled - range[Camera.Parameters.PREVIEW_FPS_MIN_INDEX];<br>            int deltaMax = desiredPreviewFpsScaled - range[Camera.Parameters.PREVIEW_FPS_MAX_INDEX];<br>            int diff = Math.abs(deltaMin) + Math.abs(deltaMax);<br>            if (diff < minDiff) {<br>                selectedFpsRange = range;<br>                minDiff = diff;<br>            }<br>        }<br>        return selectedFpsRange;<br>    }<br><br>    /**<br>     * Calculates the correct rotation for the given camera id and sets the rotation in the<br>     * parameters.  It also sets the camera's display orientation and rotation.<br>     *<br>     * @param parameters the camera parameters for which to set the rotation<br>     * @param cameraId   the camera id to set rotation based on<br>     */<br>    private void setRotation(Camera camera, Camera.Parameters parameters, int cameraId) {<br>        WindowManager windowManager =<br>                (WindowManager) context.getSystemService(Context.WINDOW_SERVICE);<br>        int degrees = 0;<br>        int rotation = windowManager.getDefaultDisplay().getRotation();<br>        switch (rotation) {<br>            case Surface.ROTATION_0:<br>                degrees = 0;<br>                break;<br>            case Surface.ROTATION_90:<br>                degrees = 90;<br>                break;<br>            case Surface.ROTATION_180:<br>                degrees = 180;<br>                break;<br>            case Surface.ROTATION_270:<br>                degrees = 270;<br>                break;<br>            default:<br>                Log.e(TAG, "Bad rotation value: " + rotation);<br>        }<br><br>        CameraInfo cameraInfo = new CameraInfo();<br>        Camera.getCameraInfo(cameraId, cameraInfo);<br><br>        int angle;<br>        int displayAngle;<br>        if (cameraInfo.facing == Camera.CameraInfo.CAMERA_FACING_FRONT) {<br>            angle = (cameraInfo.orientation + degrees) % 360;<br>            displayAngle = (360 - angle); // compensate for it being mirrored<br>        } else {  // back-facing<br>            angle = (cameraInfo.orientation - degrees + 360) % 360;<br>            displayAngle = angle;<br>        }<br><br>        // This corresponds to the rotation constants in {@link Frame}.<br>        this.rotation = angle / 90;<br><br>        camera.setDisplayOrientation(displayAngle);<br>        parameters.setRotation(angle);<br>    }<br><br>    /**<br>     * Creates one buffer for the camera preview callback.  The size of the buffer is based off of<br>     * the camera preview size and the format of the camera image.<br>     *<br>     * @return a new preview buffer of the appropriate size for the current camera settings<br>     */<br>    private byte[] createPreviewBuffer(Size previewSize) {<br>        int bitsPerPixel = ImageFormat.getBitsPerPixel(ImageFormat.NV21);<br>        long sizeInBits = previewSize.getHeight() * previewSize.getWidth() * bitsPerPixel;<br>        int bufferSize = (int) Math.ceil(sizeInBits / 8.0d) + 1;<br><br>        //<br>        // NOTICE: This code only works when using play services v. 8.1 or higher.<br>        //<br><br>        // Creating the byte array this way and wrapping it, as opposed to using .allocate(),<br>        // should guarantee that there will be an array to work with.<br>        byte[] byteArray = new byte[bufferSize];<br>        ByteBuffer buffer = ByteBuffer.wrap(byteArray);<br>        if (!buffer.hasArray() || (buffer.array() != byteArray)) {<br>            // I don't think that this will ever happen.  But if it does, then we wouldn't be<br>            // passing the preview content to the underlying detector later.<br>            throw new IllegalStateException("Failed to create valid buffer for camera source.");<br>        }<br><br>        bytesToByteBuffer.put(byteArray, buffer);<br>        return byteArray;<br>    }<br><br>    //==============================================================================================<br>    // Frame processing<br>    //==============================================================================================<br><br>    /**<br>     * Called when the camera has a new preview frame.<br>     */<br>    private class CameraPreviewCallback implements Camera.PreviewCallback {<br>        @Override<br>        public void onPreviewFrame(byte[] data, Camera camera) {<br>            frameProcessor.setNextFrame(data, camera);<br>        }<br>    }<br><br>    /**<br>     * This runnable controls access to the underlying receiver, calling it to process frames when<br>     * available from the camera.  This is designed to run detection on frames as fast as possible<br>     * (i.e., without unnecessary context switching or waiting on the next frame).<br>     * <p/><br>     * While detection is running on a frame, new frames may be received from the camera.  As these<br>     * frames come in, the most recent frame is held onto as pending.  As soon as detection and its<br>     * associated processing are done for the previous frame, detection on the mostly recently<br>     * received frame will immediately start on the same thread.<br>     */<br>    private class FrameProcessingRunnable implements Runnable {<br>        private Detector<?> mDetector;<br>        private long mStartTimeMillis = SystemClock.elapsedRealtime();<br><br>        // This lock guards all of the member variables below.<br>        private final Object mLock = new Object();<br>        private boolean mActive = true;<br><br>        // These pending variables hold the state associated with the new frame awaiting processing.<br>        private long mPendingTimeMillis;<br>        private int mPendingFrameId = 0;<br>        private ByteBuffer mPendingFrameData;<br><br>        FrameProcessingRunnable(Detector<?> detector) {<br>            mDetector = detector;<br>        }<br><br>        /**<br>         * Releases the underlying receiver.  This is only safe to do after the associated thread<br>         * has completed, which is managed in camera source's release method above.<br>         */<br>        @SuppressLint("Assert")<br>        void release() {<br>            assert (processingThread.getState() == State.TERMINATED);<br>            mDetector.release();<br>            mDetector = null;<br>        }<br><br>        /**<br>         * Marks the runnable as active/not active.  Signals any blocked threads to continue.<br>         */<br>        void setActive(boolean active) {<br>            synchronized (mLock) {<br>                mActive = active;<br>                mLock.notifyAll();<br>            }<br>        }<br><br>        /**<br>         * Sets the frame data received from the camera.  This adds the previous unused frame buffer<br>         * (if present) back to the camera, and keeps a pending reference to the frame data for<br>         * future use.<br>         */<br>        void setNextFrame(byte[] data, Camera camera) {<br>            synchronized (mLock) {<br>                if (mPendingFrameData != null) {<br>                    camera.addCallbackBuffer(mPendingFrameData.array());<br>                    mPendingFrameData = null;<br>                }<br><br>                if (!bytesToByteBuffer.containsKey(data)) {<br>                    Log.d(TAG,<br>                            "Skipping frame.  Could not find ByteBuffer associated with the image " +<br>                                    "data from the camera.");<br>                    return;<br>                }<br><br>                // Timestamp and frame ID are maintained here, which will give downstream code some<br>                // idea of the timing of frames received and when frames were dropped along the way.<br>                mPendingTimeMillis = SystemClock.elapsedRealtime() - mStartTimeMillis;<br>                mPendingFrameId++;<br>                mPendingFrameData = bytesToByteBuffer.get(data);<br><br>                // Notify the processor thread if it is waiting on the next frame (see below).<br>                mLock.notifyAll();<br>            }<br>        }<br><br>        /**<br>         * As long as the processing thread is active, this executes detection on frames<br>         * continuously.  The next pending frame is either immediately available or hasn't been<br>         * received yet.  Once it is available, we transfer the frame info to local variables and<br>         * run detection on that frame.  It immediately loops back for the next frame without<br>         * pausing.<br>         * <p/><br>         * If detection takes longer than the time in between new frames from the camera, this will<br>         * mean that this loop will run without ever waiting on a frame, avoiding any context<br>         * switching or frame acquisition time latency.<br>         * <p/><br>         * If you find that this is using more CPU than you'd like, you should probably decrease the<br>         * FPS setting above to allow for some idle time in between frames.<br>         */<br>        @Override<br>        public void run() {<br>            Frame outputFrame;<br>            ByteBuffer data;<br><br>            while (true) {<br>                synchronized (mLock) {<br>                    while (mActive && (mPendingFrameData == null)) {<br>                        try {<br>                            // Wait for the next frame to be received from the camera, since we<br>                            // don't have it yet.<br>                            mLock.wait();<br>                        } catch (InterruptedException e) {<br>                            Log.d(TAG, "Frame processing loop terminated.", e);<br>                            return;<br>                        }<br>                    }<br><br>                    if (!mActive) {<br>                        // Exit the loop once this camera source is stopped or released.  We check<br>                        // this here, immediately after the wait() above, to handle the case where<br>                        // setActive(false) had been called, triggering the termination of this<br>                        // loop.<br>                        return;<br>                    }<br><br>                    outputFrame = new Frame.Builder()<br>                            .setImageData(mPendingFrameData, previewSize.getWidth(),<br>                                    previewSize.getHeight(), ImageFormat.NV21)<br>                            .setId(mPendingFrameId)<br>                            .setTimestampMillis(mPendingTimeMillis)<br>                            .setRotation(rotation)<br>                            .build();<br><br>                    // Hold onto the frame data locally, so that we can use this for detection<br>                    // below.  We need to clear mPendingFrameData to ensure that this buffer isn't<br>                    // recycled back to the camera before we are done using that data.<br>                    data = mPendingFrameData;<br>                    mPendingFrameData = null;<br>                }<br><br>                // The code below needs to run outside of synchronization, because this will allow<br>                // the camera to add pending frame(s) while we are running detection on the current<br>                // frame.<br><br>                try {<br>                    mDetector.receiveFrame(outputFrame);<br>                } catch (Throwable t) {<br>                    Log.e(TAG, "Exception thrown from receiver.", t);<br>                } finally {<br>                    camera.addCallbackBuffer(data.array());<br>                }<br>            }<br>        }<br>    }<br>}<br><br><br>CameraSourcePreview.java<br><br>package com.google.android.gms.samples.vision.ocrreader.ui.camera;<br><br>import android.Manifest;<br>import android.content.Context;<br>import android.content.res.Configuration;<br>import android.support.annotation.RequiresPermission;<br>import android.util.AttributeSet;<br>import android.util.Log;<br>import android.view.SurfaceHolder;<br>import android.view.SurfaceView;<br>import android.view.ViewGroup;<br><br>import com.google.android.gms.common.images.Size;<br><br>import java.io.IOException;<br><br>public class CameraSourcePreview extends ViewGroup {<br>    private static final String TAG = "CameraSourcePreview";<br><br>    private Context context;<br>    private SurfaceView surfaceView;<br>    private boolean startRequested;<br>    private boolean surfaceAvailable;<br>    private CameraSource cameraSource;<br><br>    private GraphicOverlay overlay;<br><br>    public CameraSourcePreview(Context context, AttributeSet attrs) {<br>        super(context, attrs);<br>        this.context = context;<br>        startRequested = false;<br>        surfaceAvailable = false;<br><br>        surfaceView = new SurfaceView(context);<br>        surfaceView.getHolder().addCallback(new SurfaceCallback());<br>        addView(surfaceView);<br>    }<br><br>    @RequiresPermission(Manifest.permission.CAMERA)<br>    public void start(CameraSource cameraSource) throws IOException, SecurityException {<br>        if (cameraSource == null) {<br>            stop();<br>        }<br><br>        this.cameraSource = cameraSource;<br><br>        if (this.cameraSource != null) {<br>            startRequested = true;<br>            startIfReady();<br>        }<br>    }<br><br>    @RequiresPermission(Manifest.permission.CAMERA)<br>    public void start(CameraSource cameraSource, GraphicOverlay overlay) throws IOException, SecurityException {<br>        this.overlay = overlay;<br>        start(cameraSource);<br>    }<br><br>    public void stop() {<br>        if (cameraSource != null) {<br>            cameraSource.stop();<br>        }<br>    }<br><br>    public void release() {<br>        if (cameraSource != null) {<br>            cameraSource.release();<br>            cameraSource = null;<br>        }<br>    }<br><br>    @RequiresPermission(Manifest.permission.CAMERA)<br>    private void startIfReady() throws IOException, SecurityException {<br>        if (startRequested && surfaceAvailable) {<br>            cameraSource.start(surfaceView.getHolder());<br>            if (overlay != null) {<br>                Size size = cameraSource.getPreviewSize();<br>                int min = Math.min(size.getWidth(), size.getHeight());<br>                int max = Math.max(size.getWidth(), size.getHeight());<br>                if (isPortraitMode()) {<br>                    // Swap width and height sizes when in portrait, since it will be rotated by<br>                    // 90 degrees<br>                    overlay.setCameraInfo(min, max, cameraSource.getCameraFacing());<br>                } else {<br>                    overlay.setCameraInfo(max, min, cameraSource.getCameraFacing());<br>                }<br>                overlay.clear();<br>            }<br>            startRequested = false;<br>        }<br>    }<br><br>    private class SurfaceCallback implements SurfaceHolder.Callback {<br>        @Override<br>        public void surfaceCreated(SurfaceHolder surface) {<br>            surfaceAvailable = true;<br>            try {<br>                startIfReady();<br>            } catch (SecurityException se) {<br>                Log.e(TAG,"Do not have permission to start the camera", se);<br>            } catch (IOException e) {<br>                Log.e(TAG, "Could not start camera source.", e);<br>            }<br>        }<br><br>        @Override<br>        public void surfaceDestroyed(SurfaceHolder surface) {<br>            surfaceAvailable = false;<br>        }<br><br>        @Override<br>        public void surfaceChanged(SurfaceHolder holder, int format, int width, int height) {<br>        }<br>    }<br><br>    @Override<br>    protected void onLayout(boolean changed, int left, int top, int right, int bottom) {<br>        int previewWidth = 320;<br>        int previewHeight = 240;<br>        if (cameraSource != null) {<br>            Size size = cameraSource.getPreviewSize();<br>            if (size != null) {<br>                previewWidth = size.getWidth();<br>                previewHeight = size.getHeight();<br>            }<br>        }<br><br>        // Swap width and height sizes when in portrait, since it will be rotated 90 degrees<br>        if (isPortraitMode()) {<br>            int tmp = previewWidth;<br>            previewWidth = previewHeight;<br>            previewHeight = tmp;<br>        }<br><br>        final int viewWidth = right - left;<br>        final int viewHeight = bottom - top;<br><br>        int childWidth;<br>        int childHeight;<br>        int childXOffset = 0;<br>        int childYOffset = 0;<br>        float widthRatio = (float) viewWidth / (float) previewWidth;<br>        float heightRatio = (float) viewHeight / (float) previewHeight;<br><br>        // To fill the view with the camera preview, while also preserving the correct aspect ratio,<br>        // it is usually necessary to slightly oversize the child and to crop off portions along one<br>        // of the dimensions.  We scale up based on the dimension requiring the most correction, and<br>        // compute a crop offset for the other dimension.<br>        if (widthRatio > heightRatio) {<br>            childWidth = viewWidth;<br>            childHeight = (int) ((float) previewHeight * widthRatio);<br>            childYOffset = (childHeight - viewHeight) / 2;<br>        } else {<br>            childWidth = (int) ((float) previewWidth * heightRatio);<br>            childHeight = viewHeight;<br>            childXOffset = (childWidth - viewWidth) / 2;<br>        }<br><br>        for (int i = 0; i < getChildCount(); ++i) {<br>            // One dimension will be cropped.  We shift child over or up by this offset and adjust<br>            // the size to maintain the proper aspect ratio.<br>            getChildAt(i).layout(<br>                    -1 * childXOffset, -1 * childYOffset,<br>                    childWidth - childXOffset, childHeight - childYOffset);<br>        }<br><br>        try {<br>            startIfReady();<br>        } catch (SecurityException se) {<br>            Log.e(TAG,"Do not have permission to start the camera", se);<br>        } catch (IOException e) {<br>            Log.e(TAG, "Could not start camera source.", e);<br>        }<br>    }<br><br>    private boolean isPortraitMode() {<br>        int orientation = context.getResources().getConfiguration().orientation;<br>        if (orientation == Configuration.ORIENTATION_LANDSCAPE) {<br>            return false;<br>        }<br>        if (orientation == Configuration.ORIENTATION_PORTRAIT) {<br>            return true;<br>        }<br><br>        Log.d(TAG, "isPortraitMode returning false by default");<br>        return false;<br>    }<br>}<br><br>GraphicOverlay.java<br><br>package com.google.android.gms.samples.vision.ocrreader.ui.camera;<br><br>import android.content.Context;<br>import android.graphics.Canvas;<br>import android.graphics.Rect;<br>import android.graphics.RectF;<br>import android.util.AttributeSet;<br>import android.view.View;<br><br>import com.google.android.gms.vision.CameraSource;<br><br>import java.util.HashSet;<br>import java.util.Set;<br><br>/**<br> * A view which renders a series of custom graphics to be overlaid on top of an associated preview<br> * (i.e., the camera preview).  The creator can add graphics objects, update the objects, and remove<br> * them, triggering the appropriate drawing and invalidation within the view.<p><br> *<br> * Supports scaling and mirroring of the graphics relative the camera's preview properties.  The<br> * idea is that detection items are expressed in terms of a preview size, but need to be scaled up<br> * to the full view size, and also mirrored in the case of the front-facing camera.<p><br> *<br> * Associated {@link Graphic} items should use the following methods to convert to view coordinates<br> * for the graphics that are drawn:<br> * <ol><br> * <li>{@link Graphic#scaleX(float)} and {@link Graphic#scaleY(float)} adjust the size of the<br> * supplied value from the preview scale to the view scale.</li><br> * <li>{@link Graphic#translateX(float)} and {@link Graphic#translateY(float)} adjust the coordinate<br> * from the preview's coordinate system to the view coordinate system.</li><br> * </ol><br> */<br>public class GraphicOverlay<T extends GraphicOverlay.Graphic> extends View {<br>    private final Object lock = new Object();<br>    private int previewWidth;<br>    private float widthScaleFactor = 1.0f;<br>    private int previewHeight;<br>    private float heightScaleFactor = 1.0f;<br>    private int facing = CameraSource.CAMERA_FACING_BACK;<br>    private Set<T> graphics = new HashSet<>();<br><br>    /**<br>     * Base class for a custom graphics object to be rendered within the graphic overlay.  Subclass<br>     * this and implement the {@link Graphic#draw(Canvas)} method to define the<br>     * graphics element.  Add instances to the overlay using {@link GraphicOverlay#add(Graphic)}.<br>     */<br>    public static abstract class Graphic {<br>        private GraphicOverlay mOverlay;<br><br>        public Graphic(GraphicOverlay overlay) {<br>            mOverlay = overlay;<br>        }<br><br>        /**<br>         * Draw the graphic on the supplied canvas.  Drawing should use the following methods to<br>         * convert to view coordinates for the graphics that are drawn:<br>         * <ol><br>         * <li>{@link Graphic#scaleX(float)} and {@link Graphic#scaleY(float)} adjust the size of<br>         * the supplied value from the preview scale to the view scale.</li><br>         * <li>{@link Graphic#translateX(float)} and {@link Graphic#translateY(float)} adjust the<br>         * coordinate from the preview's coordinate system to the view coordinate system.</li><br>         * </ol><br>         *<br>         * @param canvas drawing canvas<br>         */<br>        public abstract void draw(Canvas canvas);<br><br>        /**<br>         * Returns true if the supplied coordinates are within this graphic.<br>         */<br>        public abstract boolean contains(float x, float y);<br><br>        /**<br>         * Adjusts a horizontal value of the supplied value from the preview scale to the view<br>         * scale.<br>         */<br>        public float scaleX(float horizontal) {<br>            return horizontal * mOverlay.widthScaleFactor;<br>        }<br><br>        /**<br>         * Adjusts a vertical value of the supplied value from the preview scale to the view scale.<br>         */<br>        public float scaleY(float vertical) {<br>            return vertical * mOverlay.heightScaleFactor;<br>        }<br><br>        /**<br>         * Adjusts the x coordinate from the preview's coordinate system to the view coordinate<br>         * system.<br>         */<br>        public float translateX(float x) {<br>            if (mOverlay.facing == CameraSource.CAMERA_FACING_FRONT) {<br>                return mOverlay.getWidth() - scaleX(x);<br>            } else {<br>                return scaleX(x);<br>            }<br>        }<br><br>        /**<br>         * Adjusts the y coordinate from the preview's coordinate system to the view coordinate<br>         * system.<br>         */<br>        public float translateY(float y) {<br>            return scaleY(y);<br>        }<br><br>        /**<br>         * Returns a RectF in which the left and right parameters of the provided Rect are adjusted<br>         * by translateX, and the top and bottom are adjusted by translateY.<br>         */<br>        public RectF translateRect(RectF inputRect) {<br>            RectF returnRect = new RectF();<br><br>            returnRect.left = translateX(inputRect.left);<br>            returnRect.top = translateY(inputRect.top);<br>            returnRect.right = translateX(inputRect.right);<br>            returnRect.bottom = translateY(inputRect.bottom);<br><br>            return returnRect;<br>        }<br><br>        public void postInvalidate() {<br>            mOverlay.postInvalidate();<br>        }<br>    }<br><br>    public GraphicOverlay(Context context, AttributeSet attrs) {<br>        super(context, attrs);<br>    }<br><br>    /**<br>     * Removes all graphics from the overlay.<br>     */<br>    public void clear() {<br>        synchronized (lock) {<br>            graphics.clear();<br>        }<br>        postInvalidate();<br>    }<br><br>    /**<br>     * Adds a graphic to the overlay.<br>     */<br>    public void add(T graphic) {<br>        synchronized (lock) {<br>            graphics.add(graphic);<br>        }<br>        postInvalidate();<br>    }<br><br>    /**<br>     * Removes a graphic from the overlay.<br>     */<br>    public void remove(T graphic) {<br>        synchronized (lock) {<br>            graphics.remove(graphic);<br>        }<br>        postInvalidate();<br>    }<br><br>    /**<br>     * Returns the first graphic, if any, that exists at the provided absolute screen coordinates.<br>     * These coordinates will be offset by the relative screen position of this view.<br>     * @return First graphic containing the point, or null if no text is detected.<br>     */<br>    public T getGraphicAtLocation(float rawX, float rawY) {<br>        synchronized (lock) {<br>            // Get the position of this View so the raw location can be offset relative to the view.<br>            int[] location = new int[2];<br>            this.getLocationOnScreen(location);<br>            for (T graphic : graphics) {<br>                if (graphic.contains(rawX - location[0], rawY - location[1])) {<br>                    return graphic;<br>                }<br>            }<br>            return null;<br>        }<br>    }<br><br>    /**<br>     * Sets the camera attributes for size and facing direction, which informs how to transform<br>     * image coordinates later.<br>     */<br>    public void setCameraInfo(int previewWidth, int previewHeight, int facing) {<br>        synchronized (lock) {<br>            this.previewWidth = previewWidth;<br>            this.previewHeight = previewHeight;<br>            this.facing = facing;<br>        }<br>        postInvalidate();<br>    }<br><br>    /**<br>     * Draws the overlay with its associated graphic objects.<br>     */<br>    @Override<br>    protected void onDraw(Canvas canvas) {<br>        super.onDraw(canvas);<br><br>        synchronized (lock) {<br>            if ((previewWidth != 0) && (previewHeight != 0)) {<br>                widthScaleFactor = (float) canvas.getWidth() / (float) previewWidth;<br>                heightScaleFactor = (float) canvas.getHeight() / (float) previewHeight;<br>            }<br><br>            for (Graphic graphic : graphics) {<br>                graphic.draw(canvas);<br>            }<br>        }<br>    }<br>}<br>
